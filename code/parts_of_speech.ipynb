{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93582f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import utility_func as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d464e1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\msyed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc3d624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps over the lazy dog.\n",
      "Artificial Intelligence is transforming the world.\n",
      "It rained heavily in Karachi last night.\n",
      "Customer support resolved my issue quickly.\n",
      "Python is a versatile programming language.\n",
      "Please respond to this email as soon as possible.\n",
      "She bought a new laptop from the market.\n",
      "The food at the restaurant was delicious.\n",
      "I forgot my umbrella at the office.\n",
      "Electric vehicles are becoming popular.\n",
      "Data privacy is a growing concern in technology.\n",
      "He completed the project ahead of schedule.\n",
      "Her favorite book is on the top shelf.\n",
      "The internet connection is very slow today.\n",
      "There will be a meeting at 10:00 AM tomorrow.\n",
      "COVID-19 changed the way we work and live.\n",
      "Congratulations on your promotion!\n",
      "I will visit Dubai next month.\n",
      "The train was delayed due to heavy rain.\n",
      "Reading regularly improves your vocabulary.\n"
     ]
    }
   ],
   "source": [
    "corpus = util.readfile('../data/random_corpus.md')\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2f661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumps over the lazy dog.',\n",
       " 'Artificial Intelligence is transforming the world.',\n",
       " 'It rained heavily in Karachi last night.',\n",
       " 'Customer support resolved my issue quickly.',\n",
       " 'Python is a versatile programming language.',\n",
       " 'Please respond to this email as soon as possible.',\n",
       " 'She bought a new laptop from the market.',\n",
       " 'The food at the restaurant was delicious.',\n",
       " 'I forgot my umbrella at the office.',\n",
       " 'Electric vehicles are becoming popular.',\n",
       " 'Data privacy is a growing concern in technology.',\n",
       " 'He completed the project ahead of schedule.',\n",
       " 'Her favorite book is on the top shelf.',\n",
       " 'The internet connection is very slow today.',\n",
       " 'There will be a meeting at 10:00 AM tomorrow.',\n",
       " 'COVID-19 changed the way we work and live.',\n",
       " 'Congratulations on your promotion!',\n",
       " 'I will visit Dubai next month.',\n",
       " 'The train was delayed due to heavy rain.',\n",
       " 'Reading regularly improves your vocabulary.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = nltk.sent_tokenize(corpus)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db6167d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_set = set(stopwords.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f77e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "pos_list = []\n",
    "for doc in docs:\n",
    "    tokens = nltk.word_tokenize(doc.lower())\n",
    "    tokens = [lemma.lemmatize(tok, 'v') for tok in tokens if tok not in stop_words_set]\n",
    "    pos_list.append(nltk.pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9170a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('quick', 'JJ'), ('brown', 'NN'), ('fox', 'JJ'), ('jump', 'NN'), ('lazy', 'NN'), ('.', '.')]\n",
      "[('artificial', 'JJ'), ('intelligence', 'NN'), ('transform', 'NN'), ('world', 'NN'), ('.', '.')]\n",
      "[('rain', 'NN'), ('heavily', 'RB'), ('karachi', 'VB'), ('night', 'NN'), ('.', '.')]\n",
      "[('customer', 'NN'), ('support', 'NN'), ('resolve', 'VBP'), ('issue', 'NN'), ('quickly', 'RB'), ('.', '.')]\n",
      "[('python', 'NN'), ('versatile', 'NN'), ('program', 'NN'), ('language', 'NN'), ('.', '.')]\n",
      "[('respond', 'NN'), ('email', 'NN'), ('possible', 'JJ'), ('.', '.')]\n",
      "[('buy', 'VB'), ('laptop', 'JJ'), ('market', 'NN'), ('.', '.')]\n",
      "[('food', 'NN'), ('restaurant', 'NN'), ('delicious', 'NN'), ('.', '.')]\n",
      "[('forget', 'VB'), ('umbrella', 'JJ'), ('office', 'NN'), ('.', '.')]\n",
      "[('electric', 'JJ'), ('vehicles', 'NNS'), ('popular', 'JJ'), ('.', '.')]\n",
      "[('data', 'NNS'), ('privacy', 'NN'), ('grow', 'VBP'), ('concern', 'NN'), ('technology', 'NN'), ('.', '.')]\n",
      "[('complete', 'JJ'), ('project', 'NN'), ('ahead', 'RB'), ('schedule', 'NN'), ('.', '.')]\n",
      "[('favorite', 'JJ'), ('book', 'NN'), ('top', 'JJ'), ('shelf', 'NN'), ('.', '.')]\n",
      "[('internet', 'JJ'), ('connection', 'NN'), ('slow', 'JJ'), ('today', 'NN'), ('.', '.')]\n",
      "[('meet', 'NN'), ('10:00', 'CD'), ('tomorrow', 'NN'), ('.', '.')]\n",
      "[('covid-19', 'JJ'), ('change', 'NN'), ('work', 'NN'), ('live', 'NN'), ('.', '.')]\n",
      "[('congratulations', 'NNS'), ('promotion', 'NN'), ('!', '.')]\n",
      "[('visit', 'NN'), ('dubai', 'JJ'), ('month', 'NN'), ('.', '.')]\n",
      "[('train', 'NN'), ('delay', 'NN'), ('due', 'JJ'), ('heavy', 'JJ'), ('rain', 'NN'), ('.', '.')]\n",
      "[('read', 'VB'), ('regularly', 'RB'), ('improve', 'VB'), ('vocabulary', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for pos in pos_list:\n",
    "    print(pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
