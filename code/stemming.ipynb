{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db9df8f",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cb6ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utility_func as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2d4f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eating', 'eats', 'eaten', 'writing', 'writes', 'programming', 'programs', 'history', 'finally', 'finalize', 'studied', 'studying', 'study', 'running', 'runs', 'ran', 'runner', 'analysis', 'analyzing', 'analyzed', 'organize', 'organizing', 'organized', 'quick', 'quickly', 'slow', 'slowly', 'beautiful', 'beautifully', 'thought', 'thinking', 'understand', 'understanding', 'understood', 'development', 'develop', 'developed', 'developing', 'create', 'creating', 'created', 'creation', 'creative', 'solution', 'solving', 'solved', 'critical', 'critically', 'research', 'researcher', 'researching', 'present', 'presenting', 'presented', 'presentation']\n"
     ]
    }
   ],
   "source": [
    "corpus = util.readfile('../data/words_list.md')\n",
    "tokens = util.tokenize_words(corpus)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaba606",
   "metadata": {},
   "source": [
    "# PotterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58fe8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "805ace26",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cb29ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating : eat\n",
      "eats : eat\n",
      "eaten : eaten\n",
      "writing : write\n",
      "writes : write\n",
      "programming : program\n",
      "programs : program\n",
      "history : histori\n",
      "finally : final\n",
      "finalize : final\n",
      "studied : studi\n",
      "studying : studi\n",
      "study : studi\n",
      "running : run\n",
      "runs : run\n",
      "ran : ran\n",
      "runner : runner\n",
      "analysis : analysi\n",
      "analyzing : analyz\n",
      "analyzed : analyz\n",
      "organize : organ\n",
      "organizing : organ\n",
      "organized : organ\n",
      "quick : quick\n",
      "quickly : quickli\n",
      "slow : slow\n",
      "slowly : slowli\n",
      "beautiful : beauti\n",
      "beautifully : beauti\n",
      "thought : thought\n",
      "thinking : think\n",
      "understand : understand\n",
      "understanding : understand\n",
      "understood : understood\n",
      "development : develop\n",
      "develop : develop\n",
      "developed : develop\n",
      "developing : develop\n",
      "create : creat\n",
      "creating : creat\n",
      "created : creat\n",
      "creation : creation\n",
      "creative : creativ\n",
      "solution : solut\n",
      "solving : solv\n",
      "solved : solv\n",
      "critical : critic\n",
      "critically : critic\n",
      "research : research\n",
      "researcher : research\n",
      "researching : research\n",
      "present : present\n",
      "presenting : present\n",
      "presented : present\n",
      "presentation : present\n"
     ]
    }
   ],
   "source": [
    "for word in tokens:\n",
    "    print(f\"{word} : {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad8596",
   "metadata": {},
   "source": [
    "# RegexStemmer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c31bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a66947ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = RegexpStemmer(\"ing$|ed$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f177149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating : eat\n",
      "eats : eats\n",
      "eaten : eaten\n",
      "writing : writ\n",
      "writes : writes\n",
      "programming : programm\n",
      "programs : programs\n",
      "history : history\n",
      "finally : finally\n",
      "finalize : finalize\n",
      "studied : studi\n",
      "studying : study\n",
      "study : study\n",
      "running : runn\n",
      "runs : runs\n",
      "ran : ran\n",
      "runner : runner\n",
      "analysis : analysis\n",
      "analyzing : analyz\n",
      "analyzed : analyz\n",
      "organize : organize\n",
      "organizing : organiz\n",
      "organized : organiz\n",
      "quick : quick\n",
      "quickly : quickly\n",
      "slow : slow\n",
      "slowly : slowly\n",
      "beautiful : beautiful\n",
      "beautifully : beautifully\n",
      "thought : thought\n",
      "thinking : think\n",
      "understand : understand\n",
      "understanding : understand\n",
      "understood : understood\n",
      "development : development\n",
      "develop : develop\n",
      "developed : develop\n",
      "developing : develop\n",
      "create : create\n",
      "creating : creat\n",
      "created : creat\n",
      "creation : creation\n",
      "creative : creative\n",
      "solution : solution\n",
      "solving : solv\n",
      "solved : solv\n",
      "critical : critical\n",
      "critically : critically\n",
      "research : research\n",
      "researcher : researcher\n",
      "researching : research\n",
      "present : present\n",
      "presenting : present\n",
      "presented : present\n",
      "presentation : presentation\n"
     ]
    }
   ],
   "source": [
    "for word in tokens:\n",
    "    print(f\"{word} : {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984074cf",
   "metadata": {},
   "source": [
    "# SnowBallStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbbed3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7335bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english', ignore_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ef56966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating : eat\n",
      "eats : eat\n",
      "eaten : eaten\n",
      "writing : write\n",
      "writes : write\n",
      "programming : program\n",
      "programs : program\n",
      "history : histori\n",
      "finally : final\n",
      "finalize : final\n",
      "studied : studi\n",
      "studying : studi\n",
      "study : studi\n",
      "running : run\n",
      "runs : run\n",
      "ran : ran\n",
      "runner : runner\n",
      "analysis : analysi\n",
      "analyzing : analyz\n",
      "analyzed : analyz\n",
      "organize : organ\n",
      "organizing : organ\n",
      "organized : organ\n",
      "quick : quick\n",
      "quickly : quick\n",
      "slow : slow\n",
      "slowly : slowli\n",
      "beautiful : beauti\n",
      "beautifully : beauti\n",
      "thought : thought\n",
      "thinking : think\n",
      "understand : understand\n",
      "understanding : understand\n",
      "understood : understood\n",
      "development : develop\n",
      "develop : develop\n",
      "developed : develop\n",
      "developing : develop\n",
      "create : creat\n",
      "creating : creat\n",
      "created : creat\n",
      "creation : creation\n",
      "creative : creativ\n",
      "solution : solut\n",
      "solving : solv\n",
      "solved : solv\n",
      "critical : critic\n",
      "critically : critic\n",
      "research : research\n",
      "researcher : research\n",
      "researching : research\n",
      "present : present\n",
      "presenting : present\n",
      "presented : present\n",
      "presentation : present\n"
     ]
    }
   ],
   "source": [
    "for word in tokens:\n",
    "    print(f\"{word} : {stemmer.stem(word)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
